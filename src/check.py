#!/usr/bin/python
# -*- coding: utf-8 -*-
from RDFClosure import DeductiveClosure, RDFS_Semantics
from rdflib import Graph, URIRef, RDF, RDFS
from glob import glob
import traceback
import argparse
import os
import csv
import md5
import codecs


def check(path):

    rdfs_graph = Graph()
    rdfs_graph.load('rdf-schema.ttl', format='turtle')

    rdfs_nodes = list(rdfs_graph.all_nodes())

    with open('{}/grading.csv'.format(path), 'w') as out:
        fieldnames = ['vunetid','Assignment 2b - Grade','Assignment 2c - Grade','query','syntax','asserted','inferred','baseline','subjects_objects','predicates','inferred through schema','hash']
        fieldnames += [os.path.basename(fn) for fn in glob('../constraints/*.rq')]

        writer = csv.DictWriter(out, fieldnames)
        writer.writeheader()

        for f in glob("{}/*.ttl".format(path)):

            (basename, ext) = os.path.splitext(os.path.basename(f))

            basename = basename.split('_')[-1]
            line = {'vunetid': basename}

            print "==========\n{}\n==========".format(basename)

            try:
                with open(f, 'r') as fi:
                    contents = fi.readlines()
                    h = md5.new()
                    h.update(''.join(contents))
                    hexdigest = h.hexdigest()
            except:
                traceback.print_exc()
                print "Could not create hash of {}".format(f)

            g = Graph()
            try:
                g.load(f, format='turtle')
                line['syntax'] = 1
            except Exception as e:

                print "Could not parse {}".format(f)
                line['syntax'] = 0
                traceback.print_exc()

            # Baseline is:
            # 1. for every *new* subject, predicate or object that is a URIRef,
            #    a new triple is generated by inference rule 1
            # 2. for every *new* predicate, one additional triple is produced (subproperty of itself)
            # 3. for rdf:Property 2 more triples that define it.
            # 4. for rdf:type 2 more triples

            subjects_objects = len(set([so for so in [so for so in g.all_nodes() if type(so) == URIRef] if so not in rdfs_nodes]))
            predicates = len(set([p for p in g.predicates()]))
            baseline = subjects_objects + 2*predicates + 2 + 2

            # Only count the asserted triples that do not define any RDFS or RDF terms, or specify that some subject is of type RDFS Class or Property.
            asserted_triples = [(s, p, o) for (s, p, o) in g.triples((None,None,None)) if s not in rdfs_nodes and o not in rdfs_nodes]

            # for (s,p,o) in asserted_triples:
            #     if type(o) == URIRef:
            #         print g.qname(s), g.qname(p), g.qname(o)
            #     else:
            #         print g.qname(s), g.qname(p), o

            asserted = len(asserted_triples)

            for constraint_file in glob('../constraints/*.rq'):
                with open(constraint_file) as cf:
                    query = cf.read()

                constraint = os.path.basename(constraint_file)
                result = g.query(query)

                count = 0
                for r in result:
                    count += 1

                line[constraint] = count
                # print "{}: {}".format(constraint, count)

            try:
                DeductiveClosure(RDFS_Semantics, rdfs_closure = True, axiomatic_triples = False, datatype_axioms = False).expand(g)
            except:
                traceback.print_exc()

            inferred = len([(s, p, o) for (s, p, o) in g.triples((None,None,None))])
            class_use = len(set([s for (s, p, o) in g.triples((None, RDF.type, None)) if o not in rdfs_nodes]))
            property_use = len(set([p for (s, p, o) in asserted_triples]))

            try:
                with codecs.open('{}/{}.rq'.format(path, basename), "r", encoding='utf-8-sig', errors='ignore') as qf:
                    query = qf.read()

                # Remove CR
                query = query.replace('\r\n', '\n')
                # try:
                #     query = query.decode("utf-8-sig").encode('utf-8')
                # except:
                #     print "..."

                # This kills the RDFLib parser
                query = query.replace('prefix', 'PREFIX')

                qresults = g.query(query)
                qcount = 0
                for r in qresults:
                    qcount += 1
            except IOError as e:
                print "Could not find query"
                qcount = -2
            except:
                print "Query failed"
                try:
                    print query
                except:
                    "..."
                traceback.print_exc()
                qcount = -1

            line['query'] = qcount

            line['asserted'] = asserted # asserted triples that could not be inferred,
            line['inferred'] = inferred # total triples after inference,
            line['baseline'] = baseline # minimal expected number of new triples (baseline) for file without schema
            line['subjects_objects'] = subjects_objects
            line['predicates'] = predicates
            line['inferred through schema'] = inferred-baseline-asserted # triples inferred through the schema
            line['hash'] = hexdigest


            line = grade(line)

            writer.writerow(line)
            del(g)

def grade(line):
    grade = 0  # Max is 11, so 11 is a 5.5
    if line['syntax'] == 1:  # Parsed OK
        grade += 11
    else:
        grade += 8  # We also give points just for providing the file
        # print 'syntax', grade
    if line['inferred through schema'] > 0:
        grade += 1
        # print 'inferred', grade
    if line['count_classes.rq'] >= 4:
        grade += 1
        # print 'classes', grade
    if line['count_instances.rq'] >= 4:
        grade += 1
        # print 'instances', grade
    if line['count_properties.rq'] >= 4:
        grade += 1
        # print 'properties', grade
    if line['count_rdfslabel.rq'] >= 12:
        grade += 1
        # print 'labels', grade
    if line['count_rdfssubclassof.rq'] >= 1:
        grade += 1
        # print 'subClassOf', grade
    if line['count_rdfssubpropertyof.rq'] >= 1:
        grade += 1
        # print 'subPropertyOf', grade
    if line['count_rdftype.rq'] >= 1:
        grade += 1
        # print "type", grade
    if line['count_rdfsdomain.rq'] >= 1 and line['count_rdfsrange.rq'] >= 1:
        grade += 1
        # print "domain/range", grade

    line['Assignment 2b - Grade'] = grade

    if line['query'] > 0:  # Have results
        line['Assignment 2c - Grade'] = 10
    elif line['query'] == 0:  # Does not have results
        line['Assignment 2c - Grade'] = 5
    elif line['query'] == -1:  # Cannot be parsed
        line['Assignment 2c - Grade'] = 3
    else:  # Does not exist
        line['Assignment 2c - Grade'] = 0

    return line


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Grade Assignment 2')
    parser.add_argument('path', type=str,
                    help='the file path to the submitted files')
    args = parser.parse_args()
    check(args.path)
